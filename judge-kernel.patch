From ac30e2e02e944e01bf8426379c8a7fd7942dd88b Mon Sep 17 00:00:00 2001
From: root <root@V.DEBIAN>
Date: Thu, 20 Feb 2014 00:04:35 +0800
Subject: [PATCH 273/273] Test timer

Test hang patch

Merge RLIMIT_UTIME

Add rlimit exceed counter

Fix format

Fix member name

Test taskstats

Support RLIMIT_NPROC, RLIMIT_NOFILE
---
 drivers/staging/android/binder.c    |  2 +-
 fs/exec.c                           |  3 +++
 fs/file.c                           |  5 ++++-
 include/asm-generic/resource.h      |  2 ++
 include/linux/fdtable.h             |  7 ++++++-
 include/linux/sched.h               |  6 ++++++
 include/uapi/asm-generic/resource.h |  6 +++++-
 include/uapi/linux/taskstats.h      |  5 +++++
 kernel/exit.c                       |  3 +++
 kernel/fork.c                       | 30 ++++++++++++++++++++++++++++-
 kernel/posix-cpu-timers.c           | 38 +++++++++++++++++++++++++++++++++++++
 kernel/sched/core.c                 | 19 +++++++++++++++++++
 kernel/sys.c                        | 19 +++++++++++++++++++
 kernel/tsacct.c                     |  6 ++++++
 mm/mmap.c                           | 14 +++++++++++++-
 15 files changed, 159 insertions(+), 6 deletions(-)

diff --git a/drivers/staging/android/binder.c b/drivers/staging/android/binder.c
index eaec1da..96a312f 100644
--- a/drivers/staging/android/binder.c
+++ b/drivers/staging/android/binder.c
@@ -382,7 +382,7 @@ static int task_get_unused_fd_flags(struct binder_proc *proc, int flags)
 	rlim_cur = task_rlimit(proc->tsk, RLIMIT_NOFILE);
 	unlock_task_sighand(proc->tsk, &irqs);
 
-	return __alloc_fd(files, 0, rlim_cur, flags);
+	return __alloc_task_fd(proc->tsk, files, 0, rlim_cur, flags);
 }
 
 /*
diff --git a/fs/exec.c b/fs/exec.c
index 7ea097f..7444aa33 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1464,6 +1464,9 @@ static int do_execve_common(const char *filename,
 	 */
 	if ((current->flags & PF_NPROC_EXCEEDED) &&
 	    atomic_read(&current_user()->processes) > rlimit(RLIMIT_NPROC)) {
+		/* Count RLIMIT_NPROC exceed */
+		atomic64_inc(&current->rlim_exceed[RLIMIT_NPROC]);
+
 		retval = -EAGAIN;
 		goto out_ret;
 	}
diff --git a/fs/file.c b/fs/file.c
index 4a78f98..3197509 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -458,7 +458,7 @@ struct files_struct init_files = {
 /*
  * allocate a file descriptor, mark it busy.
  */
-int __alloc_fd(struct files_struct *files,
+int __alloc_task_fd(struct task_struct *tsk, struct files_struct *files,
 	       unsigned start, unsigned end, unsigned flags)
 {
 	unsigned int fd;
@@ -481,6 +481,9 @@ repeat:
 	 */
 	error = -EMFILE;
 	if (fd >= end)
+		/* Count RLIMIT_NOFILE exceed */
+		atomic64_inc(&tsk->rlim_exceed[RLIMIT_NOFILE]);
+
 		goto out;
 
 	error = expand_files(files, fd);
diff --git a/include/asm-generic/resource.h b/include/asm-generic/resource.h
index b4ea8f5..a74e865 100644
--- a/include/asm-generic/resource.h
+++ b/include/asm-generic/resource.h
@@ -25,6 +25,8 @@
 	[RLIMIT_NICE]		= { 0, 0 },				\
 	[RLIMIT_RTPRIO]		= { 0, 0 },				\
 	[RLIMIT_RTTIME]		= {  RLIM_INFINITY,  RLIM_INFINITY },	\
+	[RLIMIT_UTIME]		= {  RLIM_INFINITY,  RLIM_INFINITY },	\
+	[RLIMIT_HANG]		= {  RLIM_INFINITY,  RLIM_INFINITY },	\
 }
 
 #endif
diff --git a/include/linux/fdtable.h b/include/linux/fdtable.h
index 085197b..89ecd78 100644
--- a/include/linux/fdtable.h
+++ b/include/linux/fdtable.h
@@ -101,8 +101,13 @@ int iterate_fd(struct files_struct *, unsigned,
 		int (*)(const void *, struct file *, unsigned),
 		const void *);
 
-extern int __alloc_fd(struct files_struct *files,
+extern int __alloc_task_fd(struct task_struct *tsk, struct files_struct *files,
 		      unsigned start, unsigned end, unsigned flags);
+static inline int __alloc_fd(struct files_struct *files,
+		      unsigned start, unsigned end, unsigned flags)
+{
+	return __alloc_task_fd(current, files, start, end, flags);
+}
 extern void __fd_install(struct files_struct *files,
 		      unsigned int fd, struct file *file);
 extern int __close_fd(struct files_struct *files,
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 53f97eb..86d077e 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1454,6 +1454,12 @@ struct task_struct {
 	unsigned int	sequential_io;
 	unsigned int	sequential_io_avg;
 #endif
+
+	/* rlimit excced counter */
+	atomic64_t rlim_exceed[RLIM_NLIMITS];
+
+	/* RLIMIT_HANG delayed work */
+	struct delayed_work rlimit_hang_work;
 };
 
 /* Future-safe accessor for struct task_struct's cpus_allowed. */
diff --git a/include/uapi/asm-generic/resource.h b/include/uapi/asm-generic/resource.h
index f863428..a543112 100644
--- a/include/uapi/asm-generic/resource.h
+++ b/include/uapi/asm-generic/resource.h
@@ -45,7 +45,11 @@
 					   0-39 for nice level 19 .. -20 */
 #define RLIMIT_RTPRIO		14	/* maximum realtime priority */
 #define RLIMIT_RTTIME		15	/* timeout for RT tasks in us */
-#define RLIM_NLIMITS		16
+
+#define RLIMIT_UTIME		16	/* user time in usec */
+#define RLIMIT_HANG		17	/* timeout for hang in usec */
+
+#define RLIM_NLIMITS		18
 
 /*
  * SuS says limits have to be unsigned.
diff --git a/include/uapi/linux/taskstats.h b/include/uapi/linux/taskstats.h
index 2466e55..f059747 100644
--- a/include/uapi/linux/taskstats.h
+++ b/include/uapi/linux/taskstats.h
@@ -17,6 +17,7 @@
 #define _LINUX_TASKSTATS_H
 
 #include <linux/types.h>
+#include <linux/resource.h>
 
 /* Format for per-task data returned to userland when
  *	- a task exits
@@ -144,6 +145,7 @@ struct taskstats {
 	__u64	write_char;		/* bytes written */
 	__u64	read_syscalls;		/* read syscalls */
 	__u64	write_syscalls;		/* write syscalls */
+
 	/* Extended accounting fields end */
 
 #define TASKSTATS_HAS_IO_ACCOUNTING
@@ -163,6 +165,9 @@ struct taskstats {
 	/* Delay waiting for memory reclaim */
 	__u64	freepages_count;
 	__u64	freepages_delay_total;
+
+	/* rlimit exceed counter */
+	__u64	rlim_exceed[RLIM_NLIMITS];
 };
 
 
diff --git a/kernel/exit.c b/kernel/exit.c
index a949819..dd6bdd4 100644
--- a/kernel/exit.c
+++ b/kernel/exit.c
@@ -754,6 +754,9 @@ void do_exit(long code)
 				current->comm, task_pid_nr(current),
 				preempt_count());
 
+	/* Cancel queued RLIMIT_HANG delayed work */
+	cancel_delayed_work(&tsk->rlimit_hang_work);
+
 	acct_update_integrals(tsk);
 	/* sync mm's RSS info before statistics gathering */
 	if (tsk->mm)
diff --git a/kernel/fork.c b/kernel/fork.c
index dfa736c..e2dcee8 100644
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -1118,6 +1118,21 @@ init_task_pid(struct task_struct *task, enum pid_type type, struct pid *pid)
 	 task->pids[type].pid = pid;
 }
 
+/* Kill process if hang time exceeds limit. */
+static void rlimit_hang_fn(struct work_struct *w)
+{
+	struct task_struct *tsk = container_of((struct delayed_work*)w,
+		struct task_struct, rlimit_hang_work);
+	unsigned long flags;
+
+	atomic64_inc(&tsk->rlim_exceed[RLIMIT_HANG]);
+
+	if (lock_task_sighand(tsk, &flags)) {
+		__group_send_sig_info(SIGKILL, SEND_SIG_PRIV, tsk);
+		unlock_task_sighand(tsk, &flags);
+	}
+}
+
 /*
  * This creates a new process as a copy of the old one,
  * but does not actually start it yet.
@@ -1134,6 +1149,7 @@ static struct task_struct *copy_process(unsigned long clone_flags,
 					int trace)
 {
 	int retval;
+	int i;
 	struct task_struct *p;
 
 	if ((clone_flags & (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS))
@@ -1201,8 +1217,12 @@ static struct task_struct *copy_process(unsigned long clone_flags,
 	if (atomic_read(&p->real_cred->user->processes) >=
 			task_rlimit(p, RLIMIT_NPROC)) {
 		if (p->real_cred->user != INIT_USER &&
-		    !capable(CAP_SYS_RESOURCE) && !capable(CAP_SYS_ADMIN))
+		    !capable(CAP_SYS_RESOURCE) && !capable(CAP_SYS_ADMIN)) {
+			/* Count RLIMIT_NPROC exceed */
+			atomic64_inc(&p->rlim_exceed[RLIMIT_NPROC]);
+
 			goto bad_fork_free;
+		}
 	}
 	current->flags &= ~PF_NPROC_EXCEEDED;
 
@@ -1310,6 +1330,14 @@ static struct task_struct *copy_process(unsigned long clone_flags,
 	p->sequential_io_avg	= 0;
 #endif
 
+	/* Initialize rlimit exceed counter. */
+	for (i = 0; i < RLIM_NLIMITS; i++) {
+	    atomic64_set(&p->rlim_exceed[i], 0);
+	}
+
+	/* Initialize RLIMIT_HANG delayed work. */
+	INIT_DELAYED_WORK(&p->rlimit_hang_work, rlimit_hang_fn);
+
 	/* Perform scheduler related setup. Assign this task to a CPU. */
 	sched_fork(clone_flags, p);
 
diff --git a/kernel/posix-cpu-timers.c b/kernel/posix-cpu-timers.c
index c7f31aa..504cb16 100644
--- a/kernel/posix-cpu-timers.c
+++ b/kernel/posix-cpu-timers.c
@@ -1023,14 +1023,21 @@ static void check_process_timers(struct task_struct *tsk,
 			ACCESS_ONCE(sig->rlim[RLIMIT_CPU].rlim_max);
 		cputime_t x;
 		if (psecs >= hard) {
+			/* Set rlimit exceed counter to 1 */
+			atomic64_set(&tsk->rlim_exceed[RLIMIT_CPU], 1);
+
 			/*
 			 * At the hard limit, we just die.
 			 * No need to calculate anything else now.
 			 */
+
 			__group_send_sig_info(SIGKILL, SEND_SIG_PRIV, tsk);
 			return;
 		}
 		if (psecs >= soft) {
+			/* Set rlimit exceed counter to 1 */
+			atomic64_set(&tsk->rlim_exceed[RLIMIT_CPU], 1);
+
 			/*
 			 * At the soft limit, send a SIGXCPU every second.
 			 */
@@ -1046,6 +1053,37 @@ static void check_process_timers(struct task_struct *tsk,
 		}
 	}
 
+	soft = ACCESS_ONCE(sig->rlim[RLIMIT_UTIME].rlim_cur);
+	if (soft != RLIM_INFINITY) {
+		unsigned long usecs = cputime_to_usecs(utime);
+		unsigned long hard =
+			ACCESS_ONCE(sig->rlim[RLIMIT_UTIME].rlim_max);
+		if (usecs >= hard) {
+			/* Set rlimit exceed counter to 1 */
+			atomic64_set(&tsk->rlim_exceed[RLIMIT_UTIME], 1);
+
+			/*
+			 * At the hard limit, we just die.
+			 * No need to calculate anything else now.
+			 */
+			__group_send_sig_info(SIGKILL, SEND_SIG_PRIV, tsk);
+			return;
+		}
+		if (usecs >= soft) {
+			/* Set rlimit exceed counter to 1 */
+			atomic64_set(&tsk->rlim_exceed[RLIMIT_UTIME], 1);
+
+			/*
+			 * At the soft limit, send a SIGXCPU every second.
+			 */
+			__group_send_sig_info(SIGXCPU, SEND_SIG_PRIV, tsk);
+			if (soft < hard) {
+				soft++;
+				sig->rlim[RLIMIT_UTIME].rlim_cur = soft;
+			}
+		}
+	}
+
 	sig->cputime_expires.prof_exp = expires_to_cputime(prof_expires);
 	sig->cputime_expires.virt_exp = expires_to_cputime(virt_expires);
 	sig->cputime_expires.sched_exp = sched_expires;
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index c677510..dba5ff9 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -760,10 +760,28 @@ static void set_load_weight(struct task_struct *p)
 	load->inv_weight = prio_to_wmult[prio];
 }
 
+/* Update state of RLIMIT_HANG delayed work */
+static void update_rlimit_hang(struct task_struct *p)
+{
+	struct rlimit rlim = p->signal->rlim[RLIMIT_HANG];
+	
+	if (rlim.rlim_cur == RLIM_INFINITY) {
+		return;
+	}
+
+	if (p->state == TASK_INTERRUPTIBLE) {
+		schedule_delayed_work(&p->rlimit_hang_work,
+			usecs_to_jiffies(rlim.rlim_cur));
+	} else {
+		cancel_delayed_work(&p->rlimit_hang_work);
+	}
+}
+
 static void enqueue_task(struct rq *rq, struct task_struct *p, int flags)
 {
 	update_rq_clock(rq);
 	sched_info_queued(rq, p);
+	update_rlimit_hang(p);
 	p->sched_class->enqueue_task(rq, p, flags);
 }
 
@@ -771,6 +789,7 @@ static void dequeue_task(struct rq *rq, struct task_struct *p, int flags)
 {
 	update_rq_clock(rq);
 	sched_info_dequeued(rq, p);
+	update_rlimit_hang(p);
 	p->sched_class->dequeue_task(rq, p, flags);
 }
 
diff --git a/kernel/sys.c b/kernel/sys.c
index c723113..248b6ca 100644
--- a/kernel/sys.c
+++ b/kernel/sys.c
@@ -1382,6 +1382,16 @@ int do_prlimit(struct task_struct *tsk, unsigned int resource,
 			 */
 			new_rlim->rlim_cur = 1;
 		}
+
+		if (resource == RLIMIT_UTIME && new_rlim->rlim_cur == 0) {
+			/*
+			 * The caller is asking for an immediate RLIMIT_UTIME
+			 * expiry.  But we use the zero value to mean "it was
+			 * never set".  So let's cheat and make it one second
+			 * instead
+			 */
+			new_rlim->rlim_cur = 1;
+		}
 	}
 	if (!retval) {
 		if (old_rlim)
@@ -1400,6 +1410,15 @@ int do_prlimit(struct task_struct *tsk, unsigned int resource,
 	 if (!retval && new_rlim && resource == RLIMIT_CPU &&
 			 new_rlim->rlim_cur != RLIM_INFINITY)
 		update_rlimit_cpu(tsk, new_rlim->rlim_cur);
+
+	 if (!retval && new_rlim && resource == RLIMIT_UTIME &&
+			new_rlim->rlim_cur != RLIM_INFINITY) {
+		cputime_t cputime = usecs_to_cputime(new_rlim->rlim_cur);
+
+		spin_lock_irq(&tsk->sighand->siglock);
+		set_process_cpu_timer(tsk, CPUCLOCK_VIRT, &cputime,NULL);
+		spin_unlock_irq(&tsk->sighand->siglock);
+	 }
 out:
 	read_unlock(&tasklist_lock);
 	return retval;
diff --git a/kernel/tsacct.c b/kernel/tsacct.c
index a1dd9a1..543c726 100644
--- a/kernel/tsacct.c
+++ b/kernel/tsacct.c
@@ -93,6 +93,7 @@ void bacct_add_tsk(struct user_namespace *user_ns,
 void xacct_add_tsk(struct taskstats *stats, struct task_struct *p)
 {
 	struct mm_struct *mm;
+	int i;
 
 	/* convert pages-usec to Mbyte-usec */
 	stats->coremem = p->acct_rss_mem1 * PAGE_SIZE / MB;
@@ -117,6 +118,11 @@ void xacct_add_tsk(struct taskstats *stats, struct task_struct *p)
 	stats->write_bytes	= 0;
 	stats->cancelled_write_bytes = 0;
 #endif
+
+	/* copy rlimit exceed counter */
+	for (i = 0; i < RLIM_NLIMITS; i++) {
+		stats->rlim_exceed[i] = atomic64_read(&p->rlim_exceed[i]);
+	}
 }
 #undef KB
 #undef MB
diff --git a/mm/mmap.c b/mm/mmap.c
index 546db74..978b057 100644
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@ -2859,11 +2859,23 @@ int may_expand_vm(struct mm_struct *mm, unsigned long npages)
 {
 	unsigned long cur = mm->total_vm;	/* pages */
 	unsigned long lim;
+	struct task_struct *p;
 
 	lim = rlimit(RLIMIT_AS) >> PAGE_SHIFT;
 
-	if (cur + npages > lim)
+	if (cur + npages > lim) {
+
+		rcu_read_lock();
+
+		if (likely((p = rcu_dereference(mm->owner)))) {
+			atomic64_inc(&p->rlim_exceed[RLIMIT_AS]);
+		}
+
+		rcu_read_unlock();
+
 		return 0;
+	}
+
 	return 1;
 }
 
-- 
1.8.5.3

